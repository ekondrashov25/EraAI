# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# MCP Server Configuration
MCP_SERVER_HOST=localhost
MCP_SERVER_PORT=8000

# External API Configuration (for function calling)
EXTERNAL_API_BASE_URL=https://api.example.com
EXTERNAL_API_KEY=your_external_api_key_here

# Vector Database Configuration
CHROMA_DB_PATH=./chroma_db

# Logging Configuration
LOG_LEVEL=INFO

# Response token cap to avoid large generations
RESPONSE_MAX_TOKENS=600

# Soft prompt size limiter (approx chars; ~4 chars per token)
MAX_PROMPT_CHARS=28000

# RAG context size cap in characters
RAG_CONTEXT_MAX_CHARS=6000

# Conversation history cap (number of messages, excluding injected system)
MAX_HISTORY_MESSAGES=16

# Retry policy for rate limits
OPENAI_RETRY_MAX_ATTEMPTS=3
OPENAI_RETRY_BASE_DELAY_SEC=2.0

# Requests-per-minute throttling (soft client-side limiter)
OPENAI_RPM_LIMIT=0  # 0 disables
RPM_WINDOW_SEC=60

# Tokens-per-minute throttling (soft client-side limiter)
OPENAI_TPM_LIMIT=0  # 0 disables
TPM_WINDOW_SEC=60

# System Prompt Configuration
SYSTEM_PROMPT=your_system_prompt
